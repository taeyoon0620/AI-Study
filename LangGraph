LangGraphëŠ” LangChain ê¸°ë°˜ì˜ ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ë¡œ, ë¹„ìˆœì°¨ì (Non-linear) ëŒ€í™” íë¦„ì„ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ê·¸ë˜í”„ ê¸°ë°˜ì˜ AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

ğŸ”¥ LangGraphë¥¼ ì‚¬ìš©í•˜ë©´?
âœ… ì—¬ëŸ¬ LLM ì—ì´ì „íŠ¸ë¥¼ í˜‘ë ¥í•˜ë„ë¡ êµ¬ì„± ê°€ëŠ¥
âœ… ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¹„ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ì‘ì„± ê°€ëŠ¥
âœ… LangChainê³¼ ì™„ë²½í•˜ê²Œ í˜¸í™˜ë¨

ğŸš€ LangGraph ì„¤ì¹˜

pip install langgraph langchain openai
ğŸŒŸ LangGraph ê¸°ë³¸ ê°œë…
LangGraphëŠ” í¬ê²Œ **ë…¸ë“œ(Node)ì™€ ì—£ì§€(Edge)**ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

ë…¸ë“œ(Node): í•˜ë‚˜ì˜ ì‘ì—…(ì˜ˆ: LLM í˜¸ì¶œ, ë°ì´í„° ì²˜ë¦¬)
ì—£ì§€(Edge): ë…¸ë“œë¥¼ ì—°ê²°í•˜ì—¬ íë¦„ì„ ì œì–´
ğŸ“ ì˜ˆì œ 1: ê°„ë‹¨í•œ LangGraph ì›Œí¬í”Œë¡œìš°
ğŸ‘‰ ì…ë ¥ëœ ì§ˆë¬¸ì„ OpenAI GPT-4ë¡œ ì²˜ë¦¬í•˜ëŠ” ê¸°ë³¸ ê·¸ë˜í”„


import os
import openai
import langgraph
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "sk-XXXXXXX"

# LLM ì´ˆê¸°í™” (GPT-4 ì‚¬ìš©)
llm = ChatOpenAI(model_name="gpt-4", temperature=0)

# LangGraph ê·¸ë˜í”„ ë¹Œë” ìƒì„±
builder = langgraph.Graph()

# 1ï¸âƒ£ ì…ë ¥ì„ ë°›ì•„ GPT-4ì— ì „ë‹¬í•˜ëŠ” ë…¸ë“œ
def llm_node(inputs):
    response = llm.invoke([HumanMessage(content=inputs["question"])])
    return {"response": response.content}

# ë…¸ë“œ ì¶”ê°€
builder.add_node("ask_gpt", llm_node)

# 2ï¸âƒ£ ê·¸ë˜í”„ ì‹¤í–‰ ê²½ë¡œ ì„¤ì •
builder.set_entry_point("ask_gpt")  # ì‹œì‘ì  ì§€ì •
builder.add_edge("ask_gpt", "ask_gpt")  # ë£¨í”„ ê°€ëŠ¥ (ì˜ˆì œìš©)

# 3ï¸âƒ£ ê·¸ë˜í”„ ì‹¤í–‰ê¸° ìƒì„±
graph = builder.compile()

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
result = graph.invoke({"question": "LangGraphê°€ ë­ì•¼?"})
print(result)
ğŸ”¹ ì‹¤í–‰ ê²°ê³¼:

arduino
ë³µì‚¬
í¸ì§‘
{'response': 'LangGraphëŠ” LangChain ê¸°ë°˜ì˜ ê·¸ë˜í”„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤...'}
ğŸŒŸ ì˜ˆì œ 2: ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„
ğŸ‘‰ "ì§ˆë¬¸ ë¶„ì„ â†’ GPT-4 ì²˜ë¦¬ â†’ ê²°ê³¼ ì •ë¦¬"ì˜ ë©€í‹° ë…¸ë“œ ê·¸ë˜í”„

import os
import langgraph
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "sk-XXXXXXX"

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model_name="gpt-4", temperature=0)

# LangGraph ê·¸ë˜í”„ ë¹Œë” ìƒì„±
builder = langgraph.Graph()

# 1ï¸âƒ£ ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” ë…¸ë“œ
def analyze_question(inputs):
    question = inputs["question"]
    if "ì½”ë”©" in question:
        return {"category": "coding", "question": question}
    else:
        return {"category": "general", "question": question}

builder.add_node("analyze_question", analyze_question)

# 2ï¸âƒ£ GPT-4ë¥¼ í˜¸ì¶œí•˜ëŠ” ë…¸ë“œ
def ask_gpt(inputs):
    response = llm.invoke([HumanMessage(content=inputs["question"])])
    return {"response": response.content}

builder.add_node("ask_gpt", ask_gpt)

# 3ï¸âƒ£ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ëŠ” ë…¸ë“œ
def summarize_response(inputs):
    return {"summary": f"GPT-4ì˜ ë‹µë³€: {inputs['response']}"}

builder.add_node("summarize_response", summarize_response)

# 4ï¸âƒ£ ê·¸ë˜í”„ ì‹¤í–‰ ê²½ë¡œ ì„¤ì •
builder.set_entry_point("analyze_question")
builder.add_edge("analyze_question", "ask_gpt")  # ì§ˆë¬¸ ë¶„ì„ í›„ GPT-4 í˜¸ì¶œ
builder.add_edge("ask_gpt", "summarize_response")  # ì‘ë‹µì„ ìš”ì•½

# 5ï¸âƒ£ ê·¸ë˜í”„ ì‹¤í–‰ê¸° ìƒì„±
graph = builder.compile()

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
result = graph.invoke({"question": "íŒŒì´ì¬ì—ì„œ í´ë˜ìŠ¤ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?"})
print(result)
ğŸ”¹ ì‹¤í–‰ ê²°ê³¼:

{'summary': 'GPT-4ì˜ ë‹µë³€: íŒŒì´ì¬ì—ì„œ í´ë˜ìŠ¤ëŠ” `class` í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì˜í•©ë‹ˆë‹¤...'}
ğŸŒŸ ì‘ìš© ì•„ì´ë””ì–´
LangGraphë¥¼ í™œìš©í•´ ë‹¤ì–‘í•œ AI ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”!
âœ… AI ìƒë‹´ ì±—ë´‡ (ì§ˆë¬¸ ë¶„ì„ â†’ ê°ì • ì¸ì‹ â†’ GPT ì‘ë‹µ)
âœ… ìë™ ì½”ë“œ ë¦¬ë·° ì‹œìŠ¤í…œ (ì½”ë“œ ë¶„ì„ â†’ ë¦¬íŒ©í† ë§ ì¶”ì²œ â†’ ìŠ¤íƒ€ì¼ ì²´í¬)
âœ… ë©€í‹° ì—ì´ì „íŠ¸ AI í˜‘ì—… ì‹œìŠ¤í…œ (ê¸°íš â†’ ì½”ë”© â†’ ë¬¸ì„œí™” ìë™í™”)

LangGraphë¡œ AI ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•˜ê³  ë” ë³µì¡í•œ AI ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë³´ì„¸ìš”! ğŸš€
ì¶”ê°€ ì§ˆë¬¸ ìˆìœ¼ë©´ í¸í•˜ê²Œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”. ğŸ˜Š







